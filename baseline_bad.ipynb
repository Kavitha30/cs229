{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('complete_dataset.txt', sep='\\t')\n",
    "data = pd.read_csv('lc_test.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.emp_length != 'na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emp_length'].replace(' 1 year', 1, inplace = True)\n",
    "data['emp_length'].replace('1 year', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns.difference(['loan_status'])].values\n",
    "y = data['loan_status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahn 1/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "lr = LogisticRegression()\n",
    "model = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998554147187816\n",
      "0.9999677205894221\n",
      "0.9756944444444444\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "testlen = X_test.shape[0]\n",
    "print(sum([pred[i] == y_test[i] for i in range(testlen)]) / float(testlen))\n",
    "\n",
    "# Specificity: For those who didn't default, how many did it predict correctly?\n",
    "print(sum([pred[i] == y_test[i] and pred[i] == 0 for i in range(testlen)]) / float(sum([pred[i] == 0 for i in range(testlen)])))\n",
    "\n",
    "# Sensitivity: For those who did default, how many did it predict correctly?\n",
    "print(sum([pred[i] == y_test[i] and pred[i] == 1 for i in range(testlen)]) / float(sum([pred[i] == 1 for i in range(testlen)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998554147187816\n",
      "[[61957     7]\n",
      " [    2   281]]\n",
      "0.9964099466851035\n"
     ]
    }
   ],
   "source": [
    "# generate metrics\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, pred))\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(metrics.roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L1, L2 logistic regression\n",
    "from sklearn import linear_model\n",
    "best_alpha = -1\n",
    "best_score = -1\n",
    "for beta in np.arange(0.1, 1, 0.05):\n",
    "    clf = linear_model.Lasso(alpha=beta).fit(X_train,y_train)\n",
    "    #print(clf.score(X, y))\n",
    "    y_hat = clf.predict(X_train)\n",
    "    MSE = np.sum((y_hat - y_train)**2)/len(X_train)\n",
    "    if clf.score(X_train, y_train) > best_score:\n",
    "        best_alpha = beta\n",
    "        best_score = clf.score(X_train,y_train)\n",
    "print(best_score)\n",
    "print(best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation\n",
    "best_alpha = -1\n",
    "best_score = -1\n",
    "batch_size = int(X_val.shape[0] / 5)\n",
    "for beta in np.arange(0.1, 1, 0.05):\n",
    "    R_square = 0 # the r square value for each fold\n",
    "    for i in range(5):\n",
    "        curt_X = X_val[i * batch_size: min((i+1) * batch_size, X_val.shape[0]), :]\n",
    "        curt_y = y_val[i * batch_size: min((i+1) * batch_size, X_val.shape[0])]\n",
    "        clf = linear_model.Ridge(alpha=beta).fit(curt_X, curt_y)\n",
    "        y_hat = clf.predict(curt_X)\n",
    "        MSE = np.sum((y_hat - curt_y)**2) / batch_size\n",
    "        R_square += clf.score(curt_X, curt_y)\n",
    "    if R_square > best_score:\n",
    "        best_alpha = beta\n",
    "        best_score = R_square\n",
    "print(best_score)\n",
    "print(best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "# ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "best_alpha = -1\n",
    "best_score = -1\n",
    "batch_size = int(X_train.shape[0] / 5)\n",
    "for beta in np.arange(0.1, 1, 0.05):\n",
    "    for l1_val in np.arange(0.1, 1, 0.05):\n",
    "        R_square = 0 # the r square value for each fold\n",
    "        for i in range(5):\n",
    "            curt_X = X_val[i * batch_size: min((i+1) * batch_size, X_val.shape[0]), :]\n",
    "            curt_y = y_val[i * batch_size: min((i+1) * batch_size, X_val.shape[0])]\n",
    "            clf = linear_model.Ridge(alpha=beta).fit(curt_X, curt_y)\n",
    "            y_hat = clf.predict(curt_X)\n",
    "            MSE = np.sum((y_hat - curt_y)**2) / batch_size\n",
    "            R_square += clf.score(curt_X, curt_y)\n",
    "    if R_square > best_score:\n",
    "        best_alpha = beta\n",
    "        best_score = R_square\n",
    "print(best_score)\n",
    "print(best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosted trees- to do rachel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# 10-fold CV, with shuffle\n",
    "kf_10 = model_selection.KFold( n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "gbr = sklearn.ensemble.GradientBoostingRegressor(random_state=0)\n",
    "result = []\n",
    "best_result = 10\n",
    "best_params = None\n",
    "best_r_score = None\n",
    "for l in range(80, 100):\n",
    "    for k in range(1, 5):\n",
    "        for l_rate in np.arange(0.1, 1, 0.05):\n",
    "            regressor = GradientBoostingRegressor(random_state=0, learning_rate = l_rate, n_estimators = l , max_depth = k)\n",
    "            score = - model_selection.cross_val_score(regressor, X_train, y_train, cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "            r_score = - model_selection.cross_val_score(regressor, X_train, y_train, cv=kf_10).mean()\n",
    "            if score < best_result:\n",
    "                best_result = score\n",
    "                best_params = (l, k)\n",
    "                best_r_score = r_score\n",
    "            result.append((score, (l, k, l_rate)))\n",
    "print(best_result)\n",
    "print(best_params)\n",
    "print(best_r_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
